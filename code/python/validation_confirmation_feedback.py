Below are three new sub-sections you can drop into your trimmed-down Section 10.1 (immediately after the Performance Report and before Calibration), to address the MU and DI reviewer comments. Feel free to tweak figure/table numbering as needed.

10.1.7 Validation-Confirmation Use Case & Workflow
The Validation-Confirmation step is the final gating operation in our end-to-end pipeline. It runs after document classification and field extraction, and before ingesting results into downstream systems. If the VC model returns { "decision": "no" }, the document is routed to a manual indexing queue for human review; if { "decision": "yes" }, processing continues automatically.

pgsql
Copy
Edit
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document      â”‚ â†’  â”‚ Classificationâ”‚ â†’  â”‚ Data Extraction        â”‚ â†’  â”‚ Validation   â”‚
â”‚ Ingestion     â”‚    â”‚ (type-label)  â”‚    â”‚ (field values)         â”‚    â”‚ Confirmation â”‚ 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                          Yes â”‚ No
                                                                              â–¼ 
                                                                          Manual
                                                                          Indexer
Independent Step: VC does not feed back into upstream extraction; it simply confirms ownership.

Dependencies:

Classification must assign the correct document type (so we know which SoR fields to compare).

Extraction must produce the raw text (full document) and SoR metadata.

10.1.8 Sample-Size Justification
We used 172 held-out documents to estimate zero-shot VC performance. At an observed accuracy of 0.98, the 95 % confidence-interval half-width (margin of error) is:

ME
â€…â€Š
=
â€…â€Š
ğ‘§
0.975
â€‰
ğ‘
(
1
âˆ’
ğ‘
)
ğ‘›
â€…â€Š
=
â€…â€Š
1.96
Ã—
0.98
Ã—
0.02
172
â‰ˆ
0.03
(
Â±
3
%
)
ME=z 
0.975
â€‹
  
n
p(1âˆ’p)
â€‹
 
â€‹
 =1.96Ã— 
172
0.98Ã—0.02
â€‹
 
â€‹
 â‰ˆ0.03(Â±3%)
Thus we can assert, with 95 % confidence, that true accuracy lies in [95 %, 100 %]. This margin is acceptable for production gating, and we will maintain it in ongoing monitoring by re-sampling at least 172 documents per quarter.

10.1.9 Stratified Performance Metrics
We report stratification both by decision class (belongs/doesnâ€™t belong) and, going forward, by document type.

Decision Class	Precision	Recall	F1-Score	Support
belongs (yes)	0.95	1.00	0.98	81
doesnâ€™t belong (no)	1.00	0.96	0.98	91

Belongs: the model correctly confirmed 100 % of true-yes cases (no false negatives).

Doesnâ€™t belong: the model correctly rejected 96 % of true-no cases.

Next steps: in our ICM dashboard we will also break these metrics out by incoming document type (e.g. Income, Statement, W2, Death Cert, Signature Card), so we can detect drift per segment.

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document      â”‚ â†’  â”‚ Classificationâ”‚ â†’  â”‚ Data Extraction        â”‚ â†’  â”‚ Validation   â”‚
â”‚ Ingestion     â”‚    â”‚ (type-label)  â”‚    â”‚ (field values)         â”‚    â”‚ Confirmation â”‚ 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                          Yes â”‚ No
                                                                              â–¼ 
                                                                          Manual
                                                                          Indexer




  Validation Confirmation Model

Purpose: As the final step in our ESO pipeline, the validation confirmation model ensures that the extracted reference-number (or â€œkeyâ€) from a given document truly matches the authoritative record in our System of Record (SOR).

Inputs:

Split classification output (document type)

Reference-number extraction (from data-extraction model)

Process:

Query the SOR using the extracted reference-number

Compare the SOR-returned canonical fields (e.g. name, address) against the OCR-extracted values

Compute a per-field confidence score and aggregate into an overall â€œvalidationâ€ confidence

Outputs:

Validation = Yes (match above threshold)

Validation = No (mismatch or low confidence)

STP Yes/No Decision
Once validation completes, we branch on the boolean outcome:

Validation Result	Action
Yes	â€¢ â†’ Straight-Through Processing (STP)
â€“ Automatically route the document and its confirmed metadata into the downstream ingestion/indexing pipeline.
â€“ Mark record as STP-eligible in the audit log.
No	â€¢ â†’ Manual Review
â€“ Flag the document for a human-in-the-loop exception workflow.
â€“ Attach discrepancy details and confidence scores to the review ticket.

ME = zâ‚€.â‚‰â‚‡â‚… Ã— âˆš[p(1âˆ’p)/n]
   = 1.96 Ã— âˆš[(0.98 Ã— 0.02)/172]
   â‰ˆ 0.03 (Â±3 %)

